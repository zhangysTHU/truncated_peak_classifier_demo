{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python import\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, average_precision_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_kftest(X_train, y_train, X_test, y_test, SEED):    \n",
    "    # Logistic Regression params\n",
    "    lr_param_dict = {\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"C\": [1e-3, 5e-3, 1e-2, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000],\n",
    "        \"solver\": [\"liblinear\"],\n",
    "        \"random_state\": [SEED]\n",
    "    }\n",
    "\n",
    "    # Initiate Logistic Regression model\n",
    "    lr_model = LogisticRegression()\n",
    "\n",
    "    # Adjust hyper-parameters with randomized search\n",
    "    lr_rscv = RandomizedSearchCV(lr_model, lr_param_dict, n_iter=100, cv=5, verbose=0,\n",
    "                                 scoring=\"roc_auc\", random_state=SEED, n_jobs=-1)\n",
    "    lr_rscv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = lr_rscv.best_estimator_.predict(X_test)\n",
    "    y_pred_proba = lr_rscv.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    aurp = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "    return acc, auroc, f1, aurp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output result of evaluation\n",
    "def eval_output(model_perf,path):\n",
    "    with open(os.path.join(path,\"Evaluate_Result_TestSet.txt\"),'w') as f:\n",
    "        f.write(\"AUROC=%s\\tAUPRC=%s\\tAccuracy=%s\\tMCC=%s\\tRecall=%s\\tPrecision=%s\\tf1_score=%s\\n\" %\n",
    "               (model_perf[\"auroc\"],model_perf[\"auprc\"],model_perf[\"accuracy\"],model_perf[\"mcc\"],model_perf[\"recall\"],model_perf[\"precision\"],model_perf[\"f1\"]))\n",
    "        f.write(\"\\n######NOTE#######\\n\")\n",
    "        f.write(\"#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#\\n\\n\")\n",
    "        f.write(model_perf[\"class_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_kind(data_df):\n",
    "    df_y0 = data_df[data_df['label'] == 0]\n",
    "    df_y1 = data_df[data_df['label'] == 1]\n",
    "\n",
    "    # 确定两个子集中数量较少的那个\n",
    "    min_count = min(len(df_y0), len(df_y1))\n",
    "\n",
    "    # 从两个子集中随机选择等量的样本\n",
    "    df_y0_balanced = df_y0.sample(n=min_count, random_state=42) if len(df_y0) > min_count else df_y0\n",
    "    df_y1_balanced = df_y1.sample(n=min_count, random_state=42) if len(df_y1) > min_count else df_y1\n",
    "\n",
    "    # 合并这两个平衡后的子集\n",
    "    balanced_df = pd.concat([df_y0_balanced, df_y1_balanced])\n",
    "    # 打乱合并后的数据集的顺序\n",
    "    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b不进行测试集划分，直接合并所有文件\n",
    "def prepare_full_dataset(label_folder_path, sample_folder_path, features_num):\n",
    "    \"\"\"\n",
    "    直接将所有样本数据和标签合并为一个 dataset，并返回特征和标签。\n",
    "    \n",
    "    :param label_folder_path: 标签文件夹路径\n",
    "    :param sample_folder_path: 样本文件夹路径\n",
    "    :param features_num: 用于训练的特征数量\n",
    "    :return: 特征和标签的 numpy 数组\n",
    "    \"\"\"\n",
    "    # 获取所有 CSV 文件的文件名，并按文件名排序\n",
    "    label_csv_files = sorted([f for f in os.listdir(label_folder_path) if f.endswith('.csv')])\n",
    "    sample_csv_files = sorted([f for f in os.listdir(sample_folder_path) if f.endswith('.csv')])\n",
    "\n",
    "    # 用于存储所有标签和样本的 DataFrame\n",
    "    all_labels = []\n",
    "    all_samples = []\n",
    "\n",
    "    # 加载所有标签和样本文件\n",
    "    for label_file, sample_file in zip(label_csv_files, sample_csv_files):\n",
    "        all_labels.append(pd.read_csv(os.path.join(label_folder_path, label_file)))\n",
    "        all_samples.append(pd.read_csv(os.path.join(sample_folder_path, sample_file)))\n",
    "\n",
    "    # 合并所有标签和样本\n",
    "    all_labels_df = pd.concat(all_labels, axis=0)\n",
    "    all_samples_df = pd.concat(all_samples, axis=0)\n",
    "\n",
    "    # 合并样本和标签数据\n",
    "    merged_df = pd.merge(all_samples_df, all_labels_df, on='sample', how='left')\n",
    "    \n",
    "    # 调用 equal_kind 函数处理合并后的数据\n",
    "    merged_df = equal_kind(merged_df)\n",
    "\n",
    "    # 提取特征和标签\n",
    "    features = merged_df.iloc[:, 1:features_num + 1].values  # 提取特征列\n",
    "    labels = merged_df.iloc[:, -1].values  # 提取标签列\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AUROC of model\n",
    "def plot_AUROC(model_perf,path):\n",
    "    #get AUROC,FPR,TPR and threshold\n",
    "    roc_auc = model_perf[\"auroc\"]\n",
    "    fpr,tpr,threshold = model_perf[\"auroc_curve\"]\n",
    "    #return AUROC info\n",
    "    temp_df = pd.DataFrame({\"FPR\":fpr,\"TPR\":tpr})\n",
    "    temp_df.to_csv(os.path.join(path,\"AUROC_info.txt\"),header = True,index = False, sep = '\\t')\n",
    "    #plot\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='AUROC (area = %0.2f)' % roc_auc) \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"AUROC of Models\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(path,\"AUROC_TestSet.pdf\"),format = \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "SEED = 100\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with features_num = 640\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 600\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 560\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 520\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 480\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 440\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 400\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 360\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 320\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 280\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 240\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 200\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 160\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 120\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 80\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Running with features_num = 40\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Experiment completed and results saved.\n"
     ]
    }
   ],
   "source": [
    "label_folder_path = '/BioII/lulab_b/huangkeyun/zhangys/alkb-seq/resources/NomalSamples/labels/'\n",
    "sample_folder_path = '/BioII/lulab_b/huangkeyun/zhangys/alkb-seq/resources/NomalSamples/samples/'\n",
    "# 定义不同的 features_num\n",
    "features_nums = [640, 600, 560, 520, 480, 440, 400, 360, 320, 280, 240, 200, 160, 120, 80, 40]\n",
    "# features_nums = [600]\n",
    "# 结果记录\n",
    "all_results = []\n",
    "\n",
    "# 进行循环\n",
    "for features_num in features_nums:\n",
    "    print(f\"Running with features_num = {features_num}\")\n",
    "    \n",
    "    # 准备数据集\n",
    "    X, y = prepare_full_dataset(label_folder_path, sample_folder_path, features_num=features_num)\n",
    "    \n",
    "    # 五折交叉验证\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    fold_auroc = []\n",
    "    fold_F1 = []\n",
    "    fold_aurp = []\n",
    "\n",
    "    # 五折交叉验证\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        print(f\"Training fold {fold + 1}\")\n",
    "        \n",
    "        # 获取当前折的训练集和验证集\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "\n",
    "        # 在当前折上进行训练和验证\n",
    "        acc, auroc, F1, aurp = LR_kftest(X_train, y_train, X_val, y_val, SEED)\n",
    "        \n",
    "        fold_accuracies.append(acc)\n",
    "        fold_auroc.append(auroc)\n",
    "        fold_F1.append(F1)\n",
    "        fold_aurp.append(aurp)\n",
    "\n",
    "    # 计算五折的平均值和方差\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    acc_variance = np.var(fold_accuracies)\n",
    "    mean_auroc = np.mean(fold_auroc)\n",
    "    auroc_variance = np.var(fold_auroc)\n",
    "    mean_F1  = np.mean(fold_F1)\n",
    "    F1_variance = np.var(fold_F1)\n",
    "    mean_aurp = np.mean(fold_aurp)\n",
    "    aurp_variance = np.var(fold_aurp)\n",
    "\n",
    "    # 设置当前实验的结果\n",
    "    results = {\n",
    "        \"features_num\": features_num,\n",
    "        \"mean_accuracy\": mean_acc,\n",
    "        \"accuracy_variance\": acc_variance,\n",
    "        \"mean_auroc\": mean_auroc,\n",
    "        \"auroc_variance\": auroc_variance,\n",
    "        \"mean_F1\": mean_F1,\n",
    "        \"F1_variance\": F1_variance,\n",
    "        \"mean_aurp\": mean_aurp,\n",
    "        \"aurp_variance\": aurp_variance\n",
    "    }\n",
    "\n",
    "    # 将当前实验的结果添加到结果列表中\n",
    "    all_results.append(results)\n",
    "\n",
    "# 结果保存路径\n",
    "csv_file = '/BioII/lulab_b/huangkeyun/zhangys/alkb-seq/ML_models/eight_sample_11features_test/5fold_features_ablation/LR_ablation_results.csv'\n",
    "\n",
    "# 检查文件是否存在\n",
    "file_exists = os.path.isfile(csv_file)\n",
    "\n",
    "# 打开文件并追加结果\n",
    "with open(csv_file, mode='a', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=results.keys())\n",
    "    \n",
    "    # 如果文件不存在，写入标题\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "    \n",
    "    # 写入每次实验的结果\n",
    "    for result in all_results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(\"Experiment completed and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
